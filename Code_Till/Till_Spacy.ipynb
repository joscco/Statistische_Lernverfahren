{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import csv\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "nlp = spacy.load(\"de_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Die', 'der', 'PRON', 'PDS']\n",
      "[',', ',', 'PUNCT', '$,']\n",
      "['die', 'der', 'PRON', 'PRELS']\n",
      "['die', 'der', 'PRON', 'PDS']\n",
      "[',', ',', 'PUNCT', '$,']\n",
      "['die', 'der', 'PRON', 'PRELS']\n",
      "['die', 'der', 'DET', 'ART']\n",
      "['Dietriche', 'Dietriche', 'NOUN', 'NN']\n",
      "['erfunden', 'erfinden', 'VERB', 'VVPP']\n",
      "['haben', 'haben', 'AUX', 'VAFIN']\n",
      "[',', ',', 'PUNCT', '$,']\n",
      "['verurteilen', 'verurteilen', 'VERB', 'VVFIN']\n",
      "[',', ',', 'PUNCT', '$,']\n",
      "['irren', 'irren', 'VERB', 'VVFIN']\n",
      "['sich', 'sich', 'PRON', 'PRF']\n",
      "['.', '.', 'PUNCT', '$.']\n"
     ]
    }
   ],
   "source": [
    "text = \"Die, die die, die die Dietriche erfunden haben, verurteilen, irren sich.\"\n",
    "doc = nlp(text)\n",
    "for token in doc:\n",
    "    print([token.text, token.lemma_, token.pos_, token.tag_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_string(string):\n",
    "    # Replace all numbers with \"0\"\n",
    "    p1 =re.compile('[\\\\.,]*[0-9]+')  \n",
    "    temp = p1.sub('0',string)\n",
    "    p2 =re.compile('0+')\n",
    "    temp = p2.sub('0',temp)\n",
    "  \n",
    "    # Remove everything that is not a number or letter \n",
    "    p2 = re.compile(\"[^[A-Za-zÄäÖöÜüß0-9]\\\\s]\")\n",
    "    temp = p2.sub(\" \",temp)\n",
    "\n",
    "    # Shrink down to just one white space\n",
    "    p3 =re.compile(\"[\\\\s]+\")\n",
    "    temp = p3.sub(\" \", temp)\n",
    "  \n",
    "    return(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews =csv.reader(open('reviews2.csv'))\n",
    "reviews_new =csv.writer(open('reviews2_new.csv','w'))\n",
    "i=0\n",
    "for row in reviews:\n",
    "    text =clean_string(row[0])\n",
    "    doc =nlp(text)\n",
    "    if i==0:\n",
    "        reviews_new.writerow(['ID', 'Text', 'Lemma', 'Wortart', 'Tag'])\n",
    "    else:\n",
    "        for token in doc:\n",
    "            reviews_new.writerow([i ,token.text, token.lemma_, token.pos_, token.tag_])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews2 = pd.read_csv('reviews2_new.csv').assign(Anz=1)\n",
    "\n",
    "summary = pd.DataFrame(reviews2.groupby(['ID', 'Lemma', 'Wortart'])['Anz'].sum())\n",
    "summary.to_csv('reviews_lemma1.csv')\n",
    "\n",
    "summary = pd.DataFrame(reviews2.groupby(['ID', 'Wortart'])['Anz'].sum())\n",
    "summary.to_csv('reviews_pos.csv')\n",
    "\n",
    "summary = pd.DataFrame(reviews2.groupby(['ID', 'Tag'])['Anz'].sum())\n",
    "summary.to_csv('reviews_tag.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews3 = pd.read_csv('reviews2_new.csv').assign(Anz=1)\n",
    "reviews3['Lemma'] = reviews3['Lemma'].mask(reviews3['Wortart'] == 'PUNCT', reviews3['Wortart'])\n",
    "summary = pd.DataFrame(reviews3.groupby(['ID', 'Lemma'])['Anz'].sum())\n",
    "summary.to_csv('reviews_lemma2.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
